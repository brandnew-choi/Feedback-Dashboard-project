# -*- coding: utf-8 -*-
# Copyright 2024-2025 Streamlit Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import re
import json
import redis
import pandas as pd
import streamlit as st
import altair as alt
import numpy as np
from datetime import date, timedelta
from dateutil.relativedelta import relativedelta

st.set_page_config(page_title="Feedback Analysis Dashboard", page_icon=":package:", layout="wide")

"""
# :material/storage: Feedback Analysis Dashboard

ì±„ë„ê³¼ ê¸°ê°„ì„ ì„ íƒí•˜ë©´ Mnet Plus Appì— ëŒ€í•œ User í”¼ë“œë°±ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì €ì¥í•˜ëŠ” redis ì„œë²„ì—ì„œ ì¡°íšŒí•©ë‹ˆë‹¤.

"""

cols = st.columns([1, 3])

@st.cache_resource(show_spinner=False)
def get_client(host="localhost", port=6379, db=0, decode_responses=True):
    return redis.StrictRedis(host=host, port=port, db=db, decode_responses=decode_responses)

r = get_client()

DEFAULT_CHANNELS = ["google_play"]
DELIM = ":"
SUFFIX_ALL = "*"
SCAN_COUNT = 1000

def _get_qp_list(name: str, fallback: list[str]) -> list[str]:
    raw = st.query_params.get(name, ",".join(fallback))
    return [x for x in raw.split(",") if x]

def _get_qp_str(name: str, fallback: str) -> str:
    return st.query_params.get(name, fallback)

if "channels_input" not in st.session_state:
    st.session_state.channels_input = _get_qp_list("channel", DEFAULT_CHANNELS[:1])
if "horizon_input" not in st.session_state:
    st.session_state.horizon_input = _get_qp_str("horizon", "All")

def update_query_params():
    if st.session_state.channels_input:
        st.query_params["channel"] = ",".join(st.session_state.channels_input)
    else:
        st.query_params.pop("channel", None)
    st.query_params["horizon"] = st.session_state.horizon_input

def scan_all(client: redis.StrictRedis, match_pattern: str, count: int = SCAN_COUNT) -> list[str]:
    cursor = 0
    all_keys: list[str] = []
    while True:
        cursor, keys = client.scan(cursor=cursor, match=match_pattern, count=count)
        all_keys.extend(keys)
        if cursor == 0:
            break
    return all_keys

def read_value_by_type(client: redis.StrictRedis, key: str):
    t = client.type(key)
    if t == "string":
        val = client.get(key)
        try:
            return json.loads(val)
        except Exception:
            return val
    if t == "hash":
        data = client.hgetall(key)
        out = {}
        for k, v in data.items():
            try:
                out[k] = json.loads(v)
            except Exception:
                out[k] = v
        return out
    if t == "list":
        return client.lrange(key, 0, -1)
    if t == "set":
        return list(client.smembers(key))
    if t == "zset":
        return [{"member": m, "score": s} for m, s in client.zrange(key, 0, -1, withscores=True)]
    if t == "stream":
        entries = client.xrevrange(key, count=200)
        return [{"id": _id, **fields} for _id, fields in entries]
    return None

# ----------------------------
# ğŸ” ê¸°ê°„ë³„ ì ‘ë‘ì‚¬ ìƒì„± ë¡œì§
# ----------------------------
def _months_between(start_ym: str, end_ym: str) -> list[str]:
    """start_ym(YYYYMM)ë¶€í„° end_ym(YYYYMM)ê¹Œì§€ ëª¨ë“  YYYYMM ë¦¬ìŠ¤íŠ¸"""
    sy, sm = int(start_ym[:4]), int(start_ym[4:])
    ey, em = int(end_ym[:4]), int(end_ym[4:])
    y, m = sy, sm
    out = []
    while (y < ey) or (y == ey and m <= em):
        out.append(f"{y:04d}{m:02d}")
        if m == 12:
            y, m = y + 1, 1
        else:
            m += 1
    return out

def prefixes_for_horizon(horizon: str, today: date):
    # All: 2022-10 ~ ì˜¤ëŠ˜(YYYYMM)ê¹Œì§€ ì›” ì ‘ë‘ì‚¬ ìƒì„± (YYYYMM*) â†’ per_day=False
    if horizon == "All":
        start_ym = "202210"
        end_ym = today.strftime("%Y%m")
        yms = _months_between(start_ym, end_ym)
        return yms, False

    # 1 Year: ì˜¬í•´ 1ì›” ~ ì˜¤ëŠ˜(YYYYMM)ê¹Œì§€ ì›” ì ‘ë‘ì‚¬ (ì—°ë„ ëˆ„ì : YTD) â†’ per_day=False
    if horizon == "1 Year":
        start_ym = f"{today.year}01"          # ì˜ˆ: 2025-01
        end_ym = today.strftime("%Y%m")       # ì˜ˆ: 2025-10
        yms = _months_between(start_ym, end_ym)
        return yms, False

    # 1 Month: 'í•´ë‹¹ ì›” 1ì¼~ë§ì¼'ì„ ì¼ ë‹¨ìœ„(YYYYMMDD)ë¡œ ìƒì„± â†’ per_day=True
    if horizon == "1 Month":
        month_start = today.replace(day=1)
        month_end = (month_start + relativedelta(months=1)) - timedelta(days=1)
        days = (month_end - month_start).days + 1
        ymds = [(month_start + timedelta(days=i)).strftime("%Y%m%d") for i in range(days)]
        return ymds, True

    # 6 Months: ì˜¤ëŠ˜ ê¸°ì¤€ 'ì§€ë‚œ 6ê°œì›”' ì›” ì ‘ë‘ì‚¬ (ì˜¤ë˜ëœâ†’ìµœì‹ , ì˜ˆ: 202505 ~ 202510) â†’ per_day=False
    if horizon == "6 Months":
        yms = [(today - relativedelta(months=i)).strftime("%Y%m") for i in range(5, -1, -1)]
        return yms, False

    # (ìš”ì²­ì— ë”°ë¼ '3 Months', '2 Weeks' ì œê±°; '1 Week'ë§Œ ìœ ì§€)
    if horizon == "1 Week":
        ymds = [(today - timedelta(days=i)).strftime("%Y%m%d") for i in range(6, -1, -1)]
        return ymds, True

    return None, False

top_left_cell = cols[0].container(border=True, height="stretch", vertical_alignment="center")

with top_left_cell:
    channels = st.multiselect(
        "Channels",
        options=sorted(set(DEFAULT_CHANNELS) | set(st.session_state.channels_input)),
        default=st.session_state.channels_input,
        placeholder="ì¡°íšŒí•  ì±„ë„ì„ ì„ íƒ/ì¶”ê°€ (ì˜ˆ: mnetplus)",
        accept_new_options=True,
        key="channels_input",
        on_change=update_query_params
    )

with top_left_cell:
    horizon_map = {
        "All": None,
        "1 Year": "1yr",
        "6 Months": "6mo",
        "1 Month": "1mo",
        "1 Week": "1w",
    }
    horizon = st.pills(
        "Time horizon",
        options=list(horizon_map.keys()),
        default=st.session_state.horizon_input,
        key="horizon_input",
        on_change=update_query_params
    )

if not channels:
    top_left_cell.info("ì¡°íšŒí•  ì±„ë„ì„ í•˜ë‚˜ ì´ìƒ ì„ íƒí•˜ì„¸ìš”.", icon=":material/info:")
    st.stop()

right_cell = cols[1].container(border=True, height="stretch", vertical_alignment="center")

today = date.today()
prefixes, per_day = prefixes_for_horizon(horizon, today)

def build_patterns(channels: list[str], prefixes, per_day: bool, horizon: str | None = None):
    patterns = []
    if prefixes is None:
        for ch in channels:
            patterns.append(f"review:{ch}{DELIM}{SUFFIX_ALL}")
        return patterns
    for ch in channels:
        for p in prefixes:
            patterns.append(f"review:{ch}{DELIM}{p}{SUFFIX_ALL}")
    return patterns

patterns = build_patterns(channels, prefixes, per_day, horizon=horizon)

@st.cache_data(show_spinner=False)
def run_query(patterns: list[str]):
    client = get_client()
    all_keys = []
    for p in patterns:
        print("query : ", p)
        all_keys.extend(scan_all(client, p, count=SCAN_COUNT))
    all_keys = sorted(set(all_keys))

    rows, type_counter, error_count = [], {}, 0
    for k in all_keys:
        try:
            t = client.type(k)
            v = read_value_by_type(client, k)
            rows.append({"key": k, "type": t, "value": v})
            type_counter[t] = type_counter.get(t, 0) + 1
        except Exception as e:
            rows.append({"key": k, "type": "error", "value": f"âš ï¸ {e}"})
            error_count += 1
    df = pd.DataFrame(rows)
    return all_keys, df, type_counter, error_count

# ----------------------------
# ğŸ“ˆ ê·¸ë˜í”„ í—¬í¼ (All ì›” ì§‘ê³„ìš©)
# ----------------------------
def _channel_from_key(key: str) -> str | None:
    parts = key.split(DELIM, 2)  # ["review", "{channel}", "{rest}"]
    return parts[1] if len(parts) >= 2 else None

def _to_yyyymm_from_value(v) -> str | None:
    """value.review_created_at â†’ YYYYMMìœ¼ë¡œ ë³€í™˜"""
    if not isinstance(v, dict):
        return None
    raw = v.get("review_created_at")
    if raw is None:
        return None
    try:
        # epoch ìˆ«ì(s/ms) ì²˜ë¦¬
        if isinstance(raw, (int, float)) or (isinstance(raw, str) and raw.isdigit()):
            num = int(raw)
            unit = "ms" if num >= 10**12 else "s"
            ts = pd.to_datetime(num, unit=unit, errors="coerce")
            if pd.isna(ts):
                return None
            return ts.strftime("%Y%m")
    except Exception:
        pass
    # ë¬¸ìì—´ì—ì„œ ìˆ«ìë§Œ ì¶”ì¶œ í›„ ì• 8ìë¦¬ â†’ YYYYMM
    digits = "".join(re.findall(r"\d", str(raw)))
    if len(digits) >= 8:
        return digits[:6]
    return None

def build_month_series_from_values_for_all(df: pd.DataFrame, channels: list[str]) -> pd.DataFrame:
    rows = []
    if df is None or df.empty:
        return pd.DataFrame(columns=["Prefix", "Channel", "Count"])
    for _, row in df.iterrows():
        ch = _channel_from_key(row.get("key", ""))
        if not ch or ch not in channels:
            continue
        ym = _to_yyyymm_from_value(row.get("value"))
        if not ym:
            continue
        rows.append({"Prefix": ym, "Channel": ch})
    if not rows:
        return pd.DataFrame(columns=["Prefix", "Channel", "Count"])
    return (
        pd.DataFrame(rows)
        .groupby(["Prefix", "Channel"])
        .size()
        .reset_index(name="Count")
        .sort_values(["Prefix", "Channel"])
        .reset_index(drop=True)
    )

# ---- ì ‘ë‘ì‚¬(YYYYMM / YYYYMMDD)ë³„ ì§‘ê³„ (per_dayì— ë§ì¶¤) ----
def build_prefix_series(keys: list[str], per_day: bool, prefixes: list[str] | None) -> pd.DataFrame:
    """
    ë°˜í™˜: Prefix(str), Channel(str), Count(int)
    - per_day=True  -> YYYYMMDD ë‹¨ìœ„
    - per_day=False -> YYYYMM ë‹¨ìœ„
    """
    if not keys:
        return pd.DataFrame(columns=["Prefix", "Channel", "Count"])

    pat = re.compile(r"^(\d{8})" if per_day else r"^(\d{6})")
    rows = []
    for k in keys:
        parts = k.split(DELIM, 2)  # ["review", "{channel}", "{rest}"]
        if len(parts) < 3:
            continue
        ch, rest = parts[1], parts[2]

        m = pat.match(rest)
        if not m:
            continue

        prefix = m.group(1)  # YYYYMMDD or YYYYMM
        rows.append({"Prefix": prefix, "Channel": ch})

    if not rows:
        return pd.DataFrame(columns=["Prefix", "Channel", "Count"])

    dfp = pd.DataFrame(rows).groupby(["Prefix", "Channel"]).size().reset_index(name="Count")
    return dfp

# ---- í‘œì‹œìš© ì•ˆì „ ë¬¸ìì—´í™” ----
INT64_MIN = -(2**63)
INT64_MAX = (2**63) - 1
def _coerce_big_int(v):
    try:
        iv = int(v)
    except Exception:
        return v
    if iv < INT64_MIN or iv > INT64_MAX:
        return str(iv)
    return iv
def _stringify_for_grid(v):
    if isinstance(v, (dict, list, set, tuple)):
        try:
            return json.dumps(v, ensure_ascii=False, default=str)
        except Exception:
            return str(v)
    if isinstance(v, (bytes, bytearray, memoryview)):
        try:
            return bytes(v).decode("utf-8")
        except Exception:
            return repr(v)
    if isinstance(v, bool):
        return v
    if isinstance(v, int):
        return _coerce_big_int(v)
    try:
        import numpy as np
        if isinstance(v, (np.integer,)):
            return _coerce_big_int(int(v))
    except Exception:
        pass
    return v
def make_display_df(df: pd.DataFrame) -> pd.DataFrame:
    out = df.copy()
    if "key" in out.columns:
        out["key"] = out["key"].astype(str)
    if "type" in out.columns:
        out["type"] = out["type"].astype(str)
    if "value" in out.columns:
        out["value"] = out["value"].apply(_stringify_for_grid)
    return out

# ---- ë°ì´í„° ë¡œë“œ & ê·¸ë˜í”„ ----
with right_cell:
    # ìº¡ì…˜: Allì´ë©´ ìš”ì•½ í˜•íƒœë¡œ í‘œì‹œ
    # if horizon == "All" and prefixes:
    #     st.caption(f"â± ê¸°ê°„: **All** â€“ ì‚¬ìš© íŒ¨í„´: `{prefixes[0]}*` â€¦ `{prefixes[-1]}*` (ì´ {len(prefixes)}ê°œ)")
    # else:
    #     st.caption("ğŸ” ì‚¬ìš© íŒ¨í„´: " + ", ".join(f"`{p}`" for p in patterns))

    with st.spinner("Redisì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
        keys, df, type_counter, error_count = run_query(patterns)

    if not keys:
        st.warning("í•´ë‹¹ ì¡°ê±´ì— ë§ëŠ” í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    # === ê·¸ë˜í”„ ===
    series_df = build_prefix_series(keys, per_day=per_day, prefixes=prefixes)

    # Allì¼ ë•ŒëŠ” 'ê¸°ê°„ì— í•´ë‹¹í•˜ëŠ” ì ‘ë‘ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤' ë¬¸êµ¬ ì¶œë ¥í•˜ì§€ ì•ŠìŒ
    if horizon != "All" and not prefixes:
        st.info("ê¸°ê°„ì— í•´ë‹¹í•˜ëŠ” ì ‘ë‘ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.", icon=":material/info:")
    else:
        # ì„ íƒëœ ì ‘ë‘ì‚¬ ê¸°ì¤€ìœ¼ë¡œ ëˆ„ë½ êµ¬ê°„ 0ìœ¼ë¡œ ì±„ì›€
        all_rows = []
        # prefixesê°€ Noneì¼ ê°€ëŠ¥ì„± ë°©ì§€ (Allì—ì„œëŠ” ë¦¬ìŠ¤íŠ¸, ê·¸ ì™¸ì—ë„ ë¦¬ìŠ¤íŠ¸)
        fill_prefixes = prefixes or []
        for ch in channels:
            for p in fill_prefixes:
                cnt = 0
                row = series_df[(series_df["Prefix"] == p) & (series_df["Channel"] == ch)]
                if not row.empty:
                    cnt = int(row["Count"].values[0])
                all_rows.append({"Prefix": p, "Channel": ch, "Count": cnt})

        chart_df = pd.DataFrame(all_rows) if all_rows else series_df.copy()

        # ë¼ë²¨ í¬ë§·
        def format_label(p: str) -> str:
            try:
                if per_day and len(p) == 8:
                    dt = pd.to_datetime(p, format="%Y%m%d")
                    return dt.strftime("%Y %b %d")
                elif len(p) == 6:
                    dt = pd.to_datetime(p + "01", format="%Y%m%d")
                    return dt.strftime("%Y %b")
            except Exception:
                pass
            return p

        if not chart_df.empty:
            chart_df["DisplayPrefix"] = chart_df["Prefix"].apply(format_label)
            sort_order = [format_label(p) for p in fill_prefixes] if fill_prefixes else list(chart_df["DisplayPrefix"])

            chart = (
                alt.Chart(chart_df)
                .mark_line(point=True)
                .encode(
                    alt.X("DisplayPrefix:N", title="Month" if not per_day else "Date",
                          sort=sort_order, axis=alt.Axis(labelAngle=0)),
                    alt.Y("Count:Q", title="Count").scale(zero=False),
                    alt.Color("Channel:N", title="Channel"),
                    tooltip=[
                        alt.Tooltip("DisplayPrefix:N", title="Month" if not per_day else "Date"),
                        alt.Tooltip("Channel:N", title="Channel"),
                        alt.Tooltip("Count:Q", title="Count"),
                    ],
                )
                .properties(height=380)
            )
            st.altair_chart(chart, use_container_width=True)
        else:
            st.info("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.", icon=":material/info:")
            
            
# ---- ì¢Œí•˜ë‹¨ ë©”íŠ¸ë¦­ ----
bottom_left_cell = cols[0].container(border=True, height="stretch", vertical_alignment="center")
with bottom_left_cell:
    c = st.columns(2)
    c[0].metric("Matched keys", f"{len(keys):,}")
    c[1].metric("Errors", f"{error_count}")

# ---- Raw values ----            
"""
## Raw values 
"""
def _reorder_columns(df: pd.DataFrame, preferred: list[str], sort_remaining: bool = True) -> pd.DataFrame:
    """
    preferred ìˆœì„œëŒ€ë¡œ ì•ì— ë°°ì¹˜í•˜ê³ , ë‚˜ë¨¸ì§€ ì»¬ëŸ¼ì€ ë’¤ì— ë¶™ì„.
    sort_remaining=Trueë©´ ë‚˜ë¨¸ì§€ë¥¼ ì•ŒíŒŒë²³ ì •ë ¬í•´ì„œ ë¶€ì°©.
    """
    preferred = [c for c in preferred if c in df.columns]
    remaining = [c for c in df.columns if c not in preferred]
    if sort_remaining:
        remaining = sorted(remaining)
    cols = preferred + remaining
    return df[cols]

def _safe_stringify(obj):
    """dict/list ë‚´ë¶€ê¹Œì§€ ìˆœíšŒí•˜ë©° í‘œì‹œ ì•ˆì „í•œ ê°’ìœ¼ë¡œ ë³€í™˜(ì´ˆëŒ€í˜• ì •ìˆ˜ â†’ ë¬¸ìì—´ ë“±)."""
    if isinstance(obj, dict):
        return {k: _safe_stringify(v) for k, v in obj.items()}
    if isinstance(obj, list):
        return [_safe_stringify(x) for x in obj]
    # ìŠ¤ì¹¼ë¼ íƒ€ì…ì€ ê¸°ì¡´ ìœ í‹¸ ì‚¬ìš©
    return _stringify_for_grid(obj)

records = []  # dict ë˜ëŠ” list[dict]ë¥¼ í‘œì˜ ë ˆì½”ë“œë¡œ ì‚¬ìš©
others  = []  # dict ì •ê·œí™”ê°€ ì–´ë ¤ìš´ ê°’ì€ ë‹¨ì¼ ì»¬ëŸ¼ìœ¼ë¡œ í‘œì‹œ

for v in df["value"].tolist():
    v_safe = _safe_stringify(v)

    if isinstance(v_safe, dict):
        records.append(v_safe)
    elif isinstance(v_safe, list) and v_safe and all(isinstance(x, dict) for x in v_safe):
        # [{...}, {...}] í˜•íƒœë©´ ê° ì›ì†Œë¥¼ í–‰ìœ¼ë¡œ í¼ì¹¨
        records.extend(v_safe)
    else:
        # ê·¸ ì™¸ëŠ” ë‹¨ì¼ value ì»¬ëŸ¼ì— ê·¸ëŒ€ë¡œ í‘œì‹œ
        others.append({"value": v_safe if not isinstance(v_safe, (dict, list)) else json.dumps(v_safe, ensure_ascii=False)})

if records:
    # dict ê¸°ë°˜ valueë“¤ì„ ì—´ë¡œ ì •ê·œí™”
    values_df = pd.json_normalize(records, sep=".")
    # ê°•ì œ í˜•ë³€í™˜ ë°©ì§€: ì „ ì»¬ëŸ¼ object ìœ ì§€
    for col in values_df.columns:
        values_df[col] = values_df[col].astype("object")

    # === ì—´ ìˆœì„œ UI: Drag & Drop ì „ìš© ===
        default_priority = [
            "channel_name", "original_id", "original_content", "original_created_at",
            "review_created_at", "reviewer_name", "review_content",
            "rating", "like", "views", "review_id", "inserted_at"
        ]
        options = list(values_df.columns)

        # ê¸°ë³¸ ì´ˆê¸° ìˆœì„œ: default_priority ë¨¼ì €, ë‚˜ë¨¸ì§€ ë’¤
        initial = [c for c in default_priority if c in options] + [c for c in options if c not in default_priority]

        # ì´ì „ì— ì •í•´ë‘” ìˆœì„œê°€ ìˆìœ¼ë©´ ê·¸ê±¸ ì´ˆê¸°ê°’ìœ¼ë¡œ ì‚¬ìš©
        initial = st.session_state.get("col_order_drag", initial)

        preferred = initial[:]  # ê¸°ë³¸ê°’
        try:
            from streamlit_sortables import sort_items  # pip install streamlit-sortables

        except Exception:
            st.info("ë“œë˜ê·¸ UI ì»´í¬ë„ŒíŠ¸ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ í˜„ì¬ ì»¬ëŸ¼ ìˆœì„œë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.\n"
                    "íŒ¨í‚¤ì§€ ì„¤ì¹˜: `pip install streamlit-sortables`", icon=":material/info:")

    # Drag & Drop ê²°ê³¼ ìˆœì„œë¡œ ì •í™•íˆ ì¬ì •ë ¬ (ë’¤ì— ë‚¨ëŠ” ì»¬ëŸ¼ ì—†ìŒ)
    values_df = values_df[[c for c in preferred if c in values_df.columns] +
                        [c for c in values_df.columns if c not in preferred]]

    st.dataframe(values_df, use_container_width=True)

    # ë‹¤ìš´ë¡œë“œ(ì—´ ìˆœì„œ ë°˜ì˜)
    json_values = json.dumps(values_df.to_dict(orient="records"), ensure_ascii=False, indent=2)
    horizon_tag = "all" if prefixes is None else horizon.replace(" ", "").lower()
    st.download_button(
        label="ğŸ’¾ JSONìœ¼ë¡œ ì €ì¥í•˜ê¸° (values only - ì—´ ìˆœì„œ ë°˜ì˜)",
        data=json_values,
        file_name=f"redis_{'-'.join(channels)}_{horizon_tag}_values.json",
        mime="application/json",
    )

elif others:
    values_df = pd.DataFrame(others)
    for col in values_df.columns:
        values_df[col] = values_df[col].astype("object")

    with st.expander("ì—´ ìˆœì„œ ì„¤ì •", expanded=False):
        options = list(values_df.columns)
        default_selected = ["value"] if "value" in options else []

        preferred_cols = st.multiselect(
            "ìš°ì„  í‘œì‹œí•  ì—´(ìœ„ì—ì„œë¶€í„° ì ìš©, ì„ íƒ ìˆœì„œ ìœ ì§€)",
            options=options,
            default=default_selected,
            placeholder="ì˜ˆ: value",
            accept_new_options=True,
            key="others_col_order"
        )
        sort_remaining = st.checkbox("ë‚˜ë¨¸ì§€ ì—´ ì•ŒíŒŒë²³ ì •ë ¬", value=True, key="others_sort_remaining")

    preferred = [c for c in preferred_cols if c in values_df.columns]
    values_df = _reorder_columns(values_df, preferred, sort_remaining=sort_remaining)

    st.dataframe(values_df, use_container_width=True)

    json_values = json.dumps(values_df.to_dict(orient="records"), ensure_ascii=False, indent=2)
    horizon_tag = "all" if prefixes is None else horizon.replace(" ", "").lower()
    st.download_button(
        label="ğŸ’¾ JSONìœ¼ë¡œ ì €ì¥í•˜ê¸° (values only - ì—´ ìˆœì„œ ë°˜ì˜)",
        data=json_values,
        file_name=f"redis_{'-'.join(channels)}_{horizon_tag}_values.json",
        mime="application/json",
    )
else:
    st.info("í‘œì‹œí•  valueê°€ ì—†ìŠµë‹ˆë‹¤.", icon=":material/info:")
